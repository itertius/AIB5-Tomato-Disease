{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_feature_maps(model, image_path, layer_name=\"features.0\"):\n",
    "    # Load the image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Load the model\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # Register hook to capture the feature maps\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    # Attach the hook to the desired layer\n",
    "    for name, layer in model.named_modules():\n",
    "        if name == layer_name:\n",
    "            layer.register_forward_hook(get_activation(name))\n",
    "    \n",
    "    # Forward pass\n",
    "    _ = model(input_image)\n",
    "\n",
    "    # Extract feature maps\n",
    "    feature_maps = activation[layer_name].squeeze(0)\n",
    "    num_feature_maps = feature_maps.size(0)\n",
    "\n",
    "    # Plotting the feature maps\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(min(num_feature_maps, 16)):  # Show 16 feature maps max\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(feature_maps[i].cpu().numpy(), cmap='viridis')\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Feature Map {i+1}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "model = models.mobilenet_v2(pretrained=False)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)  # change 10 to your number of classes\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
    "visualize_feature_maps(model, \"/kaggle/input/your_image.jpg\", layer_name=\"features.0\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
